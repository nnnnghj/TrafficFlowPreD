{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a992787-80b1-41ae-9f02-2a0a324cefbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 设置header\n",
    "new_headers = [\n",
    "    'Timestamp', 'Station', 'District', 'Freeway', 'Direction',\n",
    "    'Lane Type', 'Station Length', 'Samples', '% Observed',\n",
    "    'Total Flow', 'Avg Occupancy', 'Avg Speed',\n",
    "    'Lane 1 Samples', 'Lane 1 Flow', 'Lane 1 Avg Occ',\n",
    "    'Lane 1 Avg Speed', 'Lane 1 Observed'\n",
    "]\n",
    "\n",
    "# 文件前缀和日期范围\n",
    "file_prefix = 'd12_text_station_5min_'\n",
    "start_date = datetime(2024, 1, 1)\n",
    "end_date = datetime(2024, 2, 1)\n",
    "\n",
    "# 创建一个空DataFrame来累积所有日期的数据\n",
    "accumulated_data = pd.DataFrame()\n",
    "\n",
    "# 生成日期列表\n",
    "date_list = [start_date + timedelta(days=x) for x in range((end_date - start_date).days + 1)]\n",
    "\n",
    "for date in date_list:\n",
    "    file_suffix = date.strftime('%Y_%m_%d')\n",
    "    file_path = f\"{file_prefix}{file_suffix}.txt.gz\"\n",
    "    try:\n",
    "        daily_data = pd.read_csv(\n",
    "            file_path,\n",
    "            compression='gzip',\n",
    "            header=None,\n",
    "            names=new_headers,\n",
    "            usecols=range(len(new_headers))\n",
    "        )\n",
    "        filtered_data = daily_data[daily_data['Station'] == 1223083].copy()\n",
    "        accumulated_data = pd.concat([accumulated_data, filtered_data], ignore_index=True)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "# 对于原始数据集\n",
    "filtered_data = accumulated_data[['Timestamp', 'Lane 1 Flow', 'Lane 1 Observed', '% Observed']].copy()\n",
    "filtered_data.rename(columns={\n",
    "    'Timestamp': '5 Minutes',\n",
    "    'Lane 1 Flow': 'Lane 1 Flow (Veh/5 Minutes)',\n",
    "    'Lane 1 Observed': '# Lane Points'\n",
    "}, inplace=True)\n",
    "filtered_data['5 Minutes'] = pd.to_datetime(filtered_data['5 Minutes'])\n",
    "filtered_data['5 Minutes'] = filtered_data['5 Minutes'].dt.strftime('%m/%d/%Y %H:%M')\n",
    "\n",
    "split_point = int(len(filtered_data) * 0.8)\n",
    "train_data = filtered_data[:split_point]\n",
    "test_data = filtered_data[split_point:]\n",
    "\n",
    "train_data.to_csv('train.csv', index=False)\n",
    "test_data.to_csv('test.csv', index=False)\n",
    "\n",
    "# 对于SAEs数据集\n",
    "saes_data = accumulated_data.drop(columns=['Station Length', 'Avg Speed', 'Lane 1 Avg Speed', 'Lane 1 Observed', '% Observed'])\n",
    "saes_data.rename(columns={\n",
    "    'Timestamp': '5 Minutes',\n",
    "    'Lane 1 Flow': 'Lane 1 Flow (Veh/5 Minutes)'\n",
    "}, inplace=True)\n",
    "saes_data['5 Minutes'] = pd.to_datetime(saes_data['5 Minutes'])\n",
    "saes_data['5 Minutes'] = saes_data['5 Minutes'].dt.strftime('%m/%d/%Y %H:%M')\n",
    "\n",
    "split_point_saes = int(len(saes_data) * 0.8)\n",
    "train_data_saes = saes_data[:split_point_saes]\n",
    "test_data_saes = saes_data[split_point_saes:]\n",
    "\n",
    "train_data_saes.to_csv('train_saes.csv', index=False)\n",
    "test_data_saes.to_csv('test_saes.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e005b633-3c53-4d23-9747-26bea0322f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
